[["index.html", "Probabilidades y estadistica (c) Prologo", " Probabilidades y estadistica (c) Stefano Miyel Ruberto Prologo El siguiente apunte es una recopilación de mis notas de la materia Probabilidades y estadistica (c), cursada en el primer cuatrimestre del año 2022. TODO: Pulir notas Agregar ejercicios de ejemplo Apendice con introduccion a R "],["introduccion-historica.html", "1 Introduccion historica", " 1 Introduccion historica Si tuviesemos que escribir una timeline de cientificos que fueron desarrollando la teoria de probabilidades o que se encontraron con problemas del ambito tendriamos algo como lo siguiente: Girolamo Cardano (The OG - Original gambler) Pierre de Fermat &amp; Blaise Pascal (El problema de los puntos | The unifinished game) Ellos fueron los que desarrollaron el concepto de probabilidad clasica https://en.wikipedia.org/wiki/Problem_of_points Charles Huygens (Tratado de juegos de azar) Pierre-Simon Laplace &amp; Daniel/Jacob/Nicolas Bernoulli https://en.wikipedia.org/wiki/St._Petersburg_paradox Legendre (Least squares method) Karl Friedrich Gauss (Distribucion normal) Andrey Kolmogorov (Axiomas de probabilidad) Karl Pearson (p-valores) William Gosset (Student t-distribution) Ronald Fisher (Una bocha de cosas) Jerzy Neyman &amp; Egon Pearson (Tests de hipotesis) Antoine Gombaud es aquel matematico que le dio pie a Fermat y a Pascal a introducirse en la probabilidad con el problema de los puntos. Tecnicamente, se le atribuye la ley de los grandes numeros a Jacob Bernoulli (Utilizando el concepto de Laplace) y el teorema central del limite al mismo Laplace. Kolmogorov formalizo la teoria de probabilidades en axiomas (Similar a lo que hizo Euclides con la geometria en su texto Elements). Al parecer, el campo de investigacion de la teoria de la probabilidad esta ligada a la investigacion de la teoria de la medida. Por lo que veo, todos los matematicos que mencione exceptuando Kolmogorov fueron parte de la “Probabilidad clasica”, mientras que este ultimo aporto a la “Teoria moderna” Problemas famosos: https://en.wikipedia.org/wiki/St._Petersburg_paradox https://en.wikipedia.org/wiki/Buffon%27s_needle_problem https://en.wikipedia.org/wiki/Birthday_problem https://en.wikipedia.org/wiki/Monty_Hall_problem https://en.wikipedia.org/wiki/Bertrand_paradox_(probability) Bibliografia http://www.glennshafer.com/assets/downloads/articles/article50.pdf "],["introducción-a-la-teoría-de-probabilidades..html", "2 Introducción a la teoría de probabilidades. 2.1 Espacio de probabilidades. 2.2 Probabilidad condicional. 2.3 Teorema de probabilidad total. 2.4 Teorema de Bayes. 2.5 Independencia de eventos.", " 2 Introducción a la teoría de probabilidades. La teoria de las probabilidades cuantifica los posibles resultados de un fenomeno aleatorio medidos mediante distribuciones de probabilidad. Fenomenos aleatorios (Son aquellas estudiadas por la probabilidad). Fenomenos no aleatorios / Fenomenos deterministicos (No hay azar involucrado). 2.1 Espacio de probabilidades. Definicion (Experimento) : Un experimento es un proceso que genera observaciones y puede ser repetido. (Y en caso de no poder ser repetido?) Definicion : Llamamos espacio de probabilidad a una tripla (\\(\\Omega\\), \\(\\Sigma\\), P) tal que \\(\\Omega\\) : Espacio muestral -&gt; Espacio (O conjunto) de todos los posibles resultados del experimento. \\(\\Sigma\\) : Eventos o sucesos -&gt; Posibles resultados del experimento (\\(\\Sigma \\subseteq \\Omega\\)). P : Probabilidad -&gt; Función definida como \\(P : \\Omega \\to [0, 1]\\) que a cada suceso le asigna una probabilidad. Un ejemplo sencillo de un espacio de probabilidad es aquel que involucra el lanzamiento de un dado de 6 caras en el experimento. El espacio muestral asociado al experimento serian todos los numeros del 1 al 6, representando cada uno a una cara del dado. Luego, como evento o suceso podemos tener los \\(C_i\\) eventos, donde \\(C_i\\) : “Sale el numero i”. Por ultimo, una posible funcion de probabilidad le puede asignar un valor de \\(\\frac{1}{2}\\) a evento \\(C_3\\) mientras que a los demas les asigna \\(\\frac{1}{8}\\). Propiedades : Operaciones con eventos. Sean A, B eventos S \\(\\subseteq\\) S -&gt; S se considera suceso cierto o seguro. \\(\\emptyset \\subseteq\\) S -&gt; \\(\\subseteq\\) se considera suceso imposible. A \\(\\cup\\) B -&gt; A \\(\\cup\\) B se considera el suceso unión (Ocurre si ocurre A o B). A \\(\\cap\\) B -&gt; A \\(\\cap\\) B Se considera el suceso intersección (Ocurre si ocurre A y B). \\(A^c\\) -&gt; \\(A^c\\) es el complemento de A (Ocurre si no ocurre A). A - B -&gt; A - B suceso diferencia (Ocurre si ocurre A y no B). Si A \\(\\cap\\) B = \\(\\emptyset\\) entonces A y B son eventos excluyentes. Definicion : Se define frecuencia relativa de A en n experimentos (Independientes y en las mismas condiciones) a \\[f_n (A) = \\frac{n_A}{n}\\] donde \\(n_A\\) es el numero de veces que ocurre el evento A. Ademas, \\[\\lim_{n -&gt; \\infty} f_n(A) = P(A)\\] Esta definicion nos permite asignar una probabilidad a un evento en particular contando las veces que este ocurrio. Algunas observaciones sobre la frecuencia relativa. Si \\(n_A = n\\) -&gt; \\(f_n(A) = 1\\) -&gt; A es el evento seguro. Si \\(n_A = 0\\) -&gt; \\(f_n(A) = 0\\) -&gt; A es el evento imposible. Si A = S -&gt; \\(f_n(A) = 1\\). Si \\(A \\cap B = \\emptyset\\) -&gt; \\[f_n(A \\cap B) = \\frac{n_A + n_B}{n} = \\frac{n_A}{n} + \\frac{n_B}{n} = f_n(A) + f_n(B)\\] 2.1.1 Axiomas de probabilidad Kolmogorov nos presenta los axiomas fundacionales para la teoría de la probabilidad, los cuales derivan de la interpretación previamente discutida. Dado un experimento y un espacio muestral S con eventos \\(A_i\\) P(A) \\(\\geq\\) 0 \\(\\forall\\) A \\(\\in\\) S P(S) = 1 Si \\(A_1, \\ldots, A_n\\) son disjuntos -&gt; \\(P(\\cup_{i = 1}^{\\infty} A_i) = \\sum_{i = 1}^{\\infty} P(A_i)\\) 2.2 Probabilidad condicional. Hay situaciones en donde queremos hallar probabilidades en base a eventos que ya ocurrieron, como por ejemplo “Cual es la probabilidad de que llueva hoy dado que ayer llovio?” Definicion : Se define probabilidad condicional a la probabilidad de que ocurra un evento A sabiendo que ocurre un evento B. Se denota P(A|B). No es necesario que haya una relación entre los eventos. Nota : Dependiendo de los datos que tengo, puedo calcular las probabilidades de los eventos elementales y luego calcular la probabilidad condicional de un evento. La probabilidad P(A|B) toma como conjunto referencial a B en vez de S, y analiza los casos en B donde ocurre A. P(- | F) is a Probability* (Lo vi en clase y lo acabo de ver en el Ross. Demostrar) Definicion : Sean A, B eventos, con P(B) &gt; 0, entonces \\[ P(A|B) = \\frac{P(A \\cap B)}{P(B)} \\] Como la probabilidad condicional es un espacio de probabilidad restringido al evento que ya ocurrio, entonces por definicion se cumplen los axioman de Kolmogorov. Definicion (Partición del espacio muestral) : Una partición de eventos \\(A_1, \\ldots, A_k\\) es una partición del espacio muestral S si \\(A_i \\cap A_j = \\emptyset\\) \\(\\forall i,j : \\mathbb{N} / i \\neq j\\) P(\\(A_i\\)) &gt; 0 \\(\\forall i : \\mathbb{N}\\) \\(\\cup_{i = 1}^{\\infty} A_i = S\\) Propiedades : Dados A, B eventos P(\\(A^c\\)) = 1 - P(A) \\(\\forall A \\in S\\) P(\\(\\emptyset\\)) = 0 A \\(\\subseteq\\) B -&gt; P(A) \\(\\leq\\) P(B) P(A \\(\\cup\\) B) = P(A) + P(B) - P(A \\(\\cap\\) B) P(A \\(\\cap\\) B) \\(\\leq\\) P(A) + P(B) Definicion (Eventos elementales) : Sea S un espacio muestral finito o infinito numerable. Se definen eventos elementales a los {E} con E \\(\\in\\) S. Observacion : \\(\\cup_{i = 1}^{\\infty} E_i = S\\) Observacion : \\(p_i = P(E_i) \\geq 0\\) \\(\\forall E \\in S\\) tal que \\(\\sum_{i = 1}^{\\infty} p_i = 1\\) -&gt; A evento / P(A) = \\(\\sum_{E \\in A} P_{E}\\) Definicion (Espacio equiprobable) : Sea un experimento aleatorio con espacio muestral S. Sea n = #S. Decimos que S es equiprobable si P(\\(E_i\\)) = p \\(\\forall i : \\mathbb{N}\\) Nota : Dado un espacio equiprobable \\[ P(S) = \\sum_{i = 1}^{n} P(E_i) = \\sum_{i = 1}^{n} p = np = 1 -&gt; p = \\frac{1}{n} = \\frac{1}{\\#S} \\] Observacion : Sea A un evento de un espacio equiprobable \\[ P(A) = \\sum_{E_i \\in A} P(E_i) = \\sum_{E_i \\in A} \\frac{1}{n} = \\frac{\\#A}{n} = \\frac{\\#A}{\\#S} \\] En espacios equiprobables los problemas se reducen a contar los elementos de un evento. 2.3 Teorema de probabilidad total. Definicion : Sea S un espacio muestral y sean \\(A_1, \\ldots, A_k\\) particiones del espacio. Sea B un evento, entonces \\[P(B) = \\sum_{i = 1}^{k} P(B | A_i) . P(A_i)\\] Pensar a S dividido en K partes. Un evento B en S puede tener resultados en diferentes particiones de S. Entonces tiene sentido pensar que P(B) es la suma de las probabilidades de cada fragmento en las particiones \\(A_i\\). 2.4 Teorema de Bayes. Definicion : Sea S un espacio muestral y sean \\(A_1, \\ldots, A_k\\) particiones del espacio. Sea B un evento tal que si P(B) &gt; 0, entonces \\[P(A_i|B) = \\frac{P(B|A_i).P(A_i)}{P(B)} = \\frac{P(B|A_i).P(A_i)}{\\sum_{i = 1}^{k} P(B | A_i) . P(A_i)} \\] 2.5 Independencia de eventos. Definicion (Eventos independientes) : Dados dos eventos A, B de un espacio. Decimos que los eventos son independientes si y solo si P(A \\(\\cap\\) B) = P(A).P(B) Proposicion : Si P(B) &gt; 0, entonces A, B independientes &lt;-&gt; P(A|B) = P(A) Nota : - Eventos excluyentes : P(A \\(\\cup\\) B) = P(A) + P(B) - Eventos independientes : P(A \\(\\cap\\) B) = P(A).P(B) Si tengo dos eventos independientes entonces no son excluyentes (??) Proposicion : Sean A, B eventos excluyentes (A \\(\\cap\\) B = \\(\\emptyset\\)) y P(A) &gt; 0, P(B) &gt; 0, entonces A y B no son independientes. Proposicion : P(B) = 0 -&gt; B es independiente de todo A con P(A) &gt; 0. Proposicion : A, B eventos independientes -&gt; A, \\(B^c\\) eventos independientes. Proposicion (Generalizacion de eventos independientes) : Sean \\(A_i, \\ldots, A_n\\) eventos. Decimos que \\(A_1, \\ldots, A_n\\) son independientes si \\[(\\forall k : \\mathbb{N})(2 \\leq k &lt; n \\wedge \\{B_i\\}_{i = 1}^{k} \\subseteq \\{A_i\\}_{i = 1}^{n} -&gt; P(\\cap_{i = 1}^{k} B_i) = \\Pi_{i = 1}^{k} P(B_i))\\] Nota : \\(\\{A_i\\}_{i = 1}^{n}\\) conjunto de eventos. "],["variables-aleatorias.html", "3 Variables aleatorias 3.1 Definicion. 3.2 Variables aleatorias discretas 3.3 Procesos de Poisson. 3.4 Variables aleatorias continuas. 3.5 Generacion de numeros aleatorios. 3.6 Funcion generadora de momentos.", " 3 Variables aleatorias 3.1 Definicion. Definicion (Variable aleatoria) : Sea S un espacio muestral asociado a un experimento. Llamamos variable aleatoria \\(X\\) a una funcion \\(X : S \\to \\mathbb{R}\\) que asocia a cada elemento de S un valor real. Definicion (Rango de una VA) : Sea \\(X\\) una VA. Llamamos rango de X al conjunto Rg(\\(X\\)) = {x \\(\\in \\mathbb{R}\\) / \\(\\exists\\) w \\(\\in\\) S / \\(X(w) = x\\)} Nota : Rg(\\(X\\)) = Im(\\(X\\)) Definicion (Funcion de probabilidad puntual) : Una funcion de probabilidad puntual (FPP) de la VA \\(X\\) es \\[p_{X}(x) = P(X = x) = P({w \\in S / X(w) = x})\\] Observacion : \\(p_{X}\\) es una probabilidad. Por lo tanto se cumplen \\(p_{X} \\geq 0\\) \\(\\forall x \\in Rg(X)\\) \\(\\sum_{x in Rg(X)} p_{X}(x) = 1\\) Definicion ( Funcion de distribucion acumulada) : Una funcion de distribucion acumulada de una VA discreta \\(X\\) con funcion de probabilidad puntual \\(p_{X}(x)\\) es \\[F_{X}(x) = P(X \\leq x) = \\sum_{y \\leq x, y \\in Rg(X)} p_{X}(y)\\] Nota : \\(F_{X}\\) es la probabilidad de que \\(X\\) tome valores menores o iguales a x. No necesariamente hay una correlacion entre un espacio muestral infinito y el rango de una variable aleatoria discreta. Propiedades : Funcion de distribucion acumulada \\(\\forall x \\in \\mathbb{Z} -&gt; F_{X}(x) \\in [0, 1]\\) \\(F_{X}\\) es una funcion monotona creciente. \\(F_{X}\\) es una funcion continua por derecha. \\(\\lim_{x -&gt; \\infty} F_{X}(x) = 1 \\qquad \\lim_{x -&gt; -\\infty} F_{X}(x) = 0\\) \\(p_{X}(x) = F_{X}(x) - F_{X}(x^-)\\) Nota : \\(F_{X}(x^-) = \\lim_{h -&gt; 0^-} F_{X}(x + h) = P(X &lt; x)\\) Proposicion : Si \\(a \\leq b\\) tales que \\(a,b \\in Rg(X)\\), entonces \\(P(a &lt; X \\leq b) = F_{X}(b) - F_{X}(a)\\) \\(P(a \\leq X \\leq b) = F_{X}(b) - F_{X}(a^-)\\) \\(P(a &lt; X &lt; b) = F_{X}(b^-) - F_{X}(a)\\) \\(P(a \\leq X &lt; b) = F_{X}(b^-) - F_{X}(a^-)\\) 3.1.1 Esperanza Definicion : Se define esperanza o valor esperado de una VA discreta a un promedio ponderado de los valores que toma la variable \\(X\\). \\[E(X) = \\sum_{x \\in Rg(X)} x . p_{X}(x)\\] Esta definicion vale siempre y cuando la suma sea finita. Es decir, \\(E(X) &lt; \\infty\\). Nota : Se puede interpretar a la esperanza como el “punto de equilibrio” de la VA. 3.1.2 Varianza Definicion (Varianza) : Se define varianza de una variable aleatoria discreta \\(X\\) con FPP \\(p_{X}(x)\\) y esperanza \\(\\mu_{X}\\) a la siguiente expresion \\[V(X) = E((x - \\mu_{X})^2) = \\sum_{x \\in Rg{X}} (x - \\mu_{X})^2 . p_{X}(x)\\] Este valor representa la dispersion de los valores alrededor de la esperanza de \\(X\\). Definicion (Desviacion estandar) : Definicion desvio estandar de \\(X\\) a \\[\\sigma_{X} = \\sqrt{V(X)}\\] Propiedades : Sean \\(X\\), \\(\\Psi\\) variables aleatorias discretas * \\(E(aX + b\\Psi) = aE(X) + bE(\\Psi) \\quad \\forall a, b \\in \\mathbb{R}\\) * Dada h : \\(\\mathbb{R} -&gt; \\mathbb{R}\\), entonces \\(E(h(X)) = \\sum_{x \\in Rg(X)} h(x).p_{X}(x)\\) Observacion : La varianza \\(V(X)\\) se puede reescribir como \\(V(X) = E(X^2) - E(X)^2\\) { NOTA Y PREGUNTA: Dadas dos variables aleatorias con la misma esperanza. Podemos determinar la varianza de cada una de ellas y ver como difieren en la variabilidad de los valores. Ahora, si tengo dos v.a con la misma esperanza Y varianza, puedo determinar una relacion entre las variables? AUTORESPUESTA: No. Tengo un experimento donde dos variables aleatorias describen dos caracteristicas distintas de mi experimento. Puede ser que cuando veamos correlacion esto me termine de cerrar. } Propiedad (Perdida de memoria) : Sea \\(X ~ G(\\alpha)\\) una distribucion geometrica y dados \\(n, m \\in \\mathbb{N}\\), entonces P(\\(X\\) &gt; n + m | \\(X\\) &gt; n) = P(\\(X\\) &gt; m) 3.2 Variables aleatorias discretas 3.2.1 Distribucion Bernoulli \\(X\\) es una VA que mide el numero de exitos en un experimento con dos posibles resultados. Exito o fracaso. Esta variable se denomina distribucion Bernoulli de parametro \\(\\alpha\\) y se denota \\(X ~ B(\\alpha)\\). Funcion de probabilidad puntual \\[p(1-p)^{k-1}\\] Funcion de distribucion acumulada \\[1 - (1 - p)^{\\lfloor k \\rfloor}\\] Esperanza \\[\\alpha\\] Varianza \\[\\alpha(1 - \\alpha)\\] 3.2.2 Distribucion binomial \\(X\\) es una VA que mide el numero de exitos en n experimentos de tipo Bernoulli de parametro \\(\\alpha\\) donde cada experimento es independiente del otro. La variable se denomina distribucion binomial con \\(\\alpha\\), n parametros y se la denota \\(X ~ Bi(\\alpha, n)\\). Funcion de probabilidad puntual \\[{n \\choose k} p^k (1 - p)^{n-k}\\] Funcion de distribucion acumulada \\[F(k) = \\sum_{i = 1}^{[x]} {n \\choose c} p^k (1 - p)^{n - k}\\] Esperanza \\[np\\] Varianza \\[np(1 - p)\\] 3.2.3 Distribucion geometrica \\(X\\) es una VA que mide el numero de repeticiones de experimentos de tipo Bernoulli hasta obtener el primer exito. Dicha VA se denomina distribucion geometrica de parametro \\(\\alpha\\) y se la denota \\(X ~ G(\\alpha)\\). El valor x \\(\\in Rg(X)\\) corresponde a la cantidad de repeticiones hasta conseguir el exito. Funcion de probabilidad puntual \\[p(1-p)^{k-1}\\] Funcion de distribucion acumulada \\[1 - (1 - p)^{\\lfloor k \\rfloor}\\] Esperanza \\[\\frac{1}{p}\\] Varianza \\[\\frac{(1-p)}{p^2}\\] 3.2.4 Distribucion hipergeometrica \\(X\\) es una VA que mide el numero de exitos de una muestra de tamanio n de un conjunto de tamanio N. Teniendo en cuenta que la eleccion de la muestra n se hace de forma equiprobable. La variable se denomina distribucion hipergeometrica de tamanio N con muestra n y e exitos. Se la denota \\(X ~ H(N, n, e)\\). Funcion de probabilidad puntual \\[\\frac{{D \\choose k} {N - D \\choose n - k}}{N \\choose n}\\] Funcion de distribucion acumulada Esperanza \\[\\frac{nD}{N}\\] Varianza \\[(\\frac{N - n}{N - 1})n \\frac{D}{N} (1 - \\frac{D}{N})\\] Notar que la distribucion hipergeometrica es valida si y solo si max(0, n -(N - D)) \\(\\leq\\) k \\(\\leq\\) min(n, D) 3.2.5 Distribucion binomial negativa \\(X\\) es una VA que mide r exitos en repeticiones de experimentos de tipo Bernoulli independientes. Esta variable se denomina distribucion binomial negativa de parametros r y p y se la denota \\(X ~ BN(r, p)\\) Funcion de probabilidad puntual \\[{k - 1 \\choose r - 1}p^r (1 - p)^{k - r}\\] Funcion de distribucion acumulada \\[F(k) = \\sum_{k = r}^{[x]} {k - 1 \\choose r - 1} p^r (1 - p)^{k - r}\\] Esperanza \\[\\frac{r}{p}\\] Varianza \\[\\frac{r(1 - p)}{p}\\] 3.2.6 Distribucion Poisson \\(X\\) es una VA binomial con \\(\\lambda = np\\), entonces cuando \\(\\lim_{n \\xrightarrow \\infty} n\\) y \\(\\lim_{p \\xrightarrow 0} p\\). Este tipo de variable se la considera una distribucion de Poisson de parametro \\(\\lambda\\) y se la denota \\(X ~ P(\\lambda)\\) Funcion de probabilidad puntual \\[\\frac{e^{-\\lambda} \\lambda^k}{k!}\\] Funcion de distribucion acumulada \\[F(k) = \\sum_{i = 0}{k} \\frac{e^{-\\lambda} \\lambda^i}{i!}\\] Esperanza \\[\\lambda\\] Varianza \\[\\lambda\\] En la distribucion binomial. Si se realizan n experimentos independientes con probabilidad de exito p, entonces cuando n y p son tales que n crece, p se achica y \\(\\lambda\\) es un valor moderado, entonces el numero de exitos se aproxima a una distribucion de Poisson 3.3 Procesos de Poisson. 3.4 Variables aleatorias continuas. Definicion : Sea \\(X\\) una variable aleatoria. Decimos que \\(X\\) es continua si existe una funcion \\(f : \\mathbb{R} \\rightarrow \\mathbb{R^+}\\) llamada funcion de densidad de \\(X\\) tal que \\[P(X \\in A) = \\int_{A} f(x) dx \\qquad \\forall A \\subseteq \\mathbb{R}\\] Propiedad : Si \\(A = [a, b]\\), entonces \\(P(a \\leq X \\leq b = \\int_{a}^{b} f(x) dx\\) Nota: Notar que \\(P(X = a) = \\int_{a}^{a} f(x) dx = 0 \\qquad \\forall a \\in \\mathbb{R}\\). Esto se debe a que no podemos determinar la probabilidad de un punto especifico. Observacion : Para que una funcion f(x) sea una funcion de densidad, debe satisfacer \\(f(x) \\geq 0 \\forall x \\in \\mathbb{R}\\) \\(\\int_{-\\infty}^{\\infty} f(x) dx = 1\\) Definicion : La funcion de distribucion acumulada de una variable aleatoria continua \\(X\\) con funcion de densidad f(x) se define para todo \\(x \\in \\mathbb{R}\\) como \\[F(x) = P(X \\leq x) = \\int_{-\\infty}^{t} f(t) dt\\] En comparacion con las funciones de distribucion de variables discretas, el grafico de esta es una funcion continua en todo su dominio. Propiedades : Funcion de distribucion acumulada continua * \\(\\forall x \\in \\mathbb{R} -&gt; F_{X}(x) \\in [0, 1]\\) * \\(F_{X}\\) es una funcion monotona creciente. * \\(F_{X}\\) es una funcion continua. * \\(\\lim_{x -&gt; \\infty} F_{X}(x) = 1 \\qquad \\lim_{x -&gt; -\\infty} F_{X}(x) = 0\\) Proposicion: Sea \\(X\\) una variable aleatoria continua con funcion de densidad f(x) y funcion de distribucion acumulada F(x), entonces \\[F&#39;(x) = \\frac{dF(x)}{dx} = f(x)\\] Definicion (Percentiles) : Propiedades : Distribuciones continuas La distribucion normal es simetrica sobre su esperanza \\(\\mu\\). Ademas, es una funcion que toma forma de campana y tiene un maximo en \\(\\mu\\) y dos punto de inflexion en \\(\\mu \\pm \\sigma\\) Sea \\(0 &lt; p &lt; 1\\), el 100p - percentil de la distribucion normal standard es el z tal que \\(\\Phi(z) = p\\) Dada una distribucion normal, entonces puedo transformar mi variable con una distribucion normal a una normal standard y viceversa \\(X ~ N(\\mu, \\sigma^2) \\rightarrow Z = \\frac{X - \\mu}{\\sigma} ~ N(0, 1)\\) \\(Z ~ N(0, 1) \\rightarrow X = \\sigma Z + \\mu ~ N(\\mu, \\sigma^2)\\) Esto nos sirve para calcular las probabilidades acumuladas de una variable \\(X\\) ya que hay una tabla para una \\(Z ~ N(0, 1)\\), y al momento de transformar la \\(X\\) nuestro borde de integracion cambia. Si \\(X ~ \\Gamma(\\alpha, \\lambda)\\) y ademas \\(a &gt; 0 \\rightarrow a X ~ \\Gamma(\\alpha, \\frac{\\lambda}{a})\\) Si \\(X ~ \\Gamma(1, \\lambda) \\rightarrow X ~ \\epsilon(\\lambda)\\) Definicion : Se define la funcion \\(\\Gamma : \\mathbb{R}_{\\geq 0} \\rightarrow \\mathbb{R}\\) como \\[\\Gamma(\\alpha) = \\int_{0}^{\\infty} x^{\\alpha - 1} e^{-x} dx$ $\\alpha &gt; 0\\] Propiedades : Funcion Gamma * Si \\(\\alpha &gt; 0\\) entonces \\(\\Gamma(\\alpha) = (\\alpha - 1)\\Gamma(\\alpha - 1)\\) * Si \\(\\alpha \\in \\mathbb{N}\\) entonces \\(\\Gamma(\\alpha) = (\\alpha - 1)!\\) * \\(\\Gamma(\\frac{1}{2}) = \\sqrt{\\pi}\\) Nota: Al momento de tener una v.a \\(\\mathcal{Y}\\) con distribucion normal que depende de otra, entonces podemos encontrar los parametros de la distribucion de \\(\\mathcal{Y}\\) comparando la esperanza y la varianza de aquella con la que la compuse. Lema: \\(X ~ N(\\mu, \\sigma^2) \\rightarrow Y = aX + b\\) implica que \\(Y ~ N(a\\mu + b, a^2\\sigma^2)\\) A continuacion se presentan algunas distribuciones famosas que se utilizaran a lo largo de la materia. 3.4.1 Distribucion uniforme (\\(X ~ U(A,B)\\)) Funcion de densidad \\[\\frac{1}{B - A}\\] Funcion de distribucion acumulada \\[\\frac{x - A}{B - A} x \\in [A, B]\\] Esperanza \\[\\frac{A + B}{2}\\] Varianza \\[\\frac{(B - A)^2}{12}\\] 3.4.2 Distribucion normal (\\(X ~ N(\\mu, \\sigma^2\\))) - Distribucion normal standard (\\(Z ~ N(0, 1\\))) Funcion de densidad \\[\\frac{1}{\\sqrt{2\\pi}\\sigma} e^{\\frac{-1}{2\\sigma^2} (x - \\mu)^2}\\] Funcion de distribucion acumulada \\[\\int_{-\\infty}^{z} 1/\\sqrt{2\\pi} e^{-t^2/2} dt\\] Esperanza \\[\\mu\\] Varianza \\[\\sigma^2\\] 3.4.3 Distribucion gamma (\\(X ~ \\Gamma(\\alpha, \\lambda)\\)) Funcion de densidad \\[\\frac{e^{-\\lambda x}x^{\\alpha - 1} \\lambda^{\\alpha} }{\\Gamma(\\alpha)}\\] Funcion de distribucion acumulada Esperanza \\[\\frac{\\alpha}{\\lambda}\\] Varianza \\[\\frac{\\alpha}{\\lambda^2}\\] 3.4.4 Distribucion exponencial (\\(X ~ \\epsilon(\\lambda)\\)) Funcion de densidad \\[f(x) = e^{-\\lambda x}\\lambda\\] Funcion de distribucion acumulada \\[1 - e^{-\\lambda x} x &gt; 0\\] Esperanza \\[\\frac{1}{\\lambda}\\] Varianza \\[\\frac{1}{\\lambda^2}\\] Propiedad (Falla de memoria de una distribucion exponencial) : Si \\(X ~ \\epsilon(\\lambda)\\), entonces \\[P( X &gt; t + s | x &gt; t) = P(X &gt; s)\\] Se puede demostrar que la exponencial es la unica variable aleatoria continua tal que vale la falla de memoria. Observacion : Relacion entre la distribucion exponencial y los procesos de Poisson No entendi… Es como si pudiese vincular una variable aleatoria continua con su forma discreta de un experimento con distribucion de Poisson Nota : \\(T_k\\) = Tiempo que demora hasta el k-esimo evento. Entonces deriva en una variable \\(\\Gamma\\) 3.4.5 Distribucion Cauchy (\\(X ~ \\epsilon(\\lambda)\\)) Despues la explico ### Distribucion T-Student (\\(X ~ \\epsilon(\\lambda)\\)) Despues la explico ### Distribucion \\(\\chi^2\\) (\\(X ~ \\epsilon(\\lambda)\\)) Despues la explico ### Distribucion Raileigh (\\(X ~ \\epsilon(\\lambda)\\)) Despues la explico ### Distribucion Pareto (\\(X ~ \\epsilon(\\lambda)\\)) Despues la explico 3.5 Generacion de numeros aleatorios. Definicion (Teorema) : Sea \\(X ~ f(x)\\) funcion de densidad tal que \\(P(x \\in (a, b)) = 1\\). Sea \\(g : (a, b) \\rightarrow \\mathbb{R}\\) tal que g es monotona creciente o monotona decreciente. Sea \\(Y = g(X)\\), entonces \\[ f_Y(y) = \\left\\{ \\begin{array}{ll} f_X[g^{-1}(y)] . (g^{-1}(y))&#39; &amp; y = g(x) \\text{ para algun x} \\\\ 0 &amp; y \\neq g(x) \\text{ para algun x} \\end{array} \\right. \\] Que g sea estrictamente creciente me determina biyectividad. Este teorema nos brinda una forma comoda de encontrar una densidad de una v.a que depende de otra. Anteriormente lo que se hacia era hallar la funcion de distribucion de \\(F_Y\\) y luego derivar la F para encontrar la densidad, ahora con este teorema sale directamente el calculo de la densidad. Corolario : En general, \\(g:\\mathbb{R} \\rightarrow \\mathbb{R}\\) tal que \\(\\exists g_i : G_i \\rightarrow \\mathbb{R}\\) y ademas es inversible \\(\\forall i / 1 \\leq i \\leq n\\) entonces \\(g(x) = g_i(x)\\) si \\(x \\in G_i\\). Observacion : El corolario nos dice que si no tenemos una funcion que es monotona, pero tiene partes donde lo hace, entonces podemos calcular la densidad como una suma de particiones. \\(f_Y(y) = \\sum_{i = 1}^n f_{X}(g_i^{-1}) . |g_i^{-1}(y)&#39;| . I_{G_i}(g_i^{-1}(y))\\) Proposicion : Sea \\(X\\) variable aleatoria continua con densidad \\(f_x\\) y acumulada \\(F_x\\). Supongamos que F es estrictamente creciente. Sea \\(\\mathcal{U} ~ \\mathcal{U}(0, 1)\\). Si \\(Y = F_x^{-1}(u)\\), entonces \\(Y ~ X\\) (No lo entendi del todo) 3.6 Funcion generadora de momentos. Me estaba olvidando que existia este tema. "],["vectores-aleatorios.html", "4 Vectores aleatorios 4.1 Vectores aleatorios discretos 4.2 Vectores aleatorios continuos 4.3 Probabilidad condicional de vectores aleatorios. 4.4 Independencia de variables aleatorias sobre un vector. 4.5 Esperanza y covarianza de vectores aleatorios.", " 4 Vectores aleatorios Dado un experimento y su espacio muestra asociado, es posible definir diferentes variables aleatorias. Asi como analizamos cada variable aleatoria de manera individual, es posible analizar varias de manera conjunta. Definicion : Sean \\(X_1, \\ldots, X_n\\) variables aleatorias, definimos un vector aleatorio al vector \\(\\mathcal{V} : \\Omega \\to \\mathbb{R}^n\\) tal que \\[ V(\\omega) = &lt;X_1(\\omega), X_2(\\omega), \\ldots, X_n(\\omega)&gt;\\] donde cada funcion coordenada es una variable aleatoria. Tipico ejemplo de X = ‘Altura de una persona’, Y = ‘Peso de una persona’. En un ejemplo de computacion podria ser la cantidad de tiempo de ejecucion y la memoria utilizada. 4.1 Vectores aleatorios discretos Observacion : Rango del vector : \\(Rg_{X Y} = \\{ (x, y) / x \\in Rg_{X}, y \\in Rg_{Y} \\wedge p_{X Y}(x, y) &gt; 0 \\}\\) (Para n = 2) \\(Rg_{X Y} \\subseteq \\{ (x, y) / x \\in Rg_{X}, y \\in Rg_{Y} \\}\\) (Para n = 2) Definicion : Sean \\(X, Y\\) variables aleatorias discretas definidas sobre un espacio muestral \\(\\mathcal{S}\\). Se define funcion de probabilidad puntual conjunta como: \\[p_{X Y}(x, y) = P(X = x, Y = y)\\] Observacion : La funcion de probabilidad conjunta es una probabilidad, por lo tanto cumple los axiomas de probabilidad \\(p_{X Y} (x, y) \\geq 0 \\forall (x, y) \\in Rg_{X Y}\\) \\(\\sum_{x \\in Rg_{X}} \\sum_{y \\in Rg_{Y}} p_{X Y} (x, y) = 1\\) Definicion : Se define funciones marginales de un vector aleatorio de dos variables como \\[p_{X}(x) = \\sum_{y \\in Y} p_{X Y} (x, y) \\qquad p_{Y}(y) = \\sum_{x \\in X} p_{X Y} (x, y)\\] Las funciones marginales me determinan las probabilidades puntuales de una variable aleatoria del vector en un valor puntual. Definicion : La funcion de distribucion acumulada conjunta de un vector aleatorio esta dado por \\[F_{X Y}(x, y) = \\sum_{s \\leq X} \\sum_{t \\leq Y} p_{X Y} (x, y) \\qquad \\forall (x, y) \\in \\mathbb{R}^2\\] Definicion : Sea \\(\\mathcal{V}\\) un vector aleatorio con variables aleatorias continuas. Decimos que el vector \\(\\mathcal{V}\\) es continuo si existe una funcion de densidad conjunta \\(f_{X Y} : \\mathbb{R}^2 \\rightarrow \\mathbb{R}^{\\geq 0}\\) tal que \\[P((X, Y) \\in A) = \\int \\int_{A} f_{X Y}(x, y) dx dy \\qquad \\forall A \\subseteq \\mathbb{R}^2\\] 4.2 Vectores aleatorios continuos Observacion : Dada una funcion de densidad conjunta \\(f_{X Y}\\). Si queremos encontrar la funcion de densidad para cualquiera de las dos variables aleatorias, debo integrar sobre la variable que no es de interes. Observacion : Dado un vector aleatorio de K coordenadas, puedo hallar las funciones de densidad para cualquier subconjunto de las variables aleatorias \\(X_i \\forall i, 0 \\leq i \\leq k-1\\) Definicion : Sea \\(\\mathcal{V}\\) un vector aleatorio continuo con funcion de densidad conjunta \\(f_{X Y}(x, y)\\). La funcion de distribucion acumulada conjunta de \\(\\mathcal{V}\\) esta dada por \\[F_{(X, Y)}(x, y) = \\int_{-\\infty}^x \\int_{-\\infty}^y f_{X Y}(s, t) ds dt \\qquad \\forall A \\subseteq \\mathbb{R}^2\\] Propiedades : Funcion de distribucion acumulada \\(\\lim_{(X_1, \\ldots, X_n) -&gt; \\infty} F((X_1, \\ldots, X_n)) = 1\\) \\(\\lim_{X_i -&gt; -\\infty} F((X_1, \\ldots, X_i ,\\ldots ,X_n)) = 0\\) para algun i Monotonia : \\(F_{X} \\leq F_{\\hat{X}}\\) si \\(X \\leq \\hat{X}\\) Esta propiedad define un orden sobre los vectores de \\(\\mathbb{R}^n\\). Vamos a decir que un vector es menor a otro si todas las coordenadas del uno son menores a las del otro. (Chequear) \\(P(a \\leq x \\leq b, c \\leq y \\leq d) = F(b, d) - F(a, d) - F(b, c) + F(a, c) \\geq 0\\) Caso contrario, entonces F no es una probabilidad. Nota : Para hallar la funcion de densidad conjunta de un vector aleatorio dada la funcion de distribucion, entonces basta con derivar F con cada una de las variables aleatorias. Duda : Es posible que, si la funcion F es \\(C^1\\), entonces tranquilamente pueda calcular la funcion de densidad conjunta derivando en cualquier orden? Respuesta : Si, pero en la practica no siempre ocurre 4.3 Probabilidad condicional de vectores aleatorios. Definicion : Sea \\(\\mathcal{V}\\) un vector aleatorio discreto con funcion de densidad conjunta \\(f_{X Y}(x, y)\\) y funciones de probabilidad marginales para cada variable aleatoria. Sea \\(x \\in X\\) tal que \\(p_{X}(x) &gt; 0\\). La funcion de probabilidad condicional de Y dado \\(X = x\\) esta dada por \\[p_{Y | X = x} (y) = \\frac{p_{X Y}(x, y)}{p_{X}(x)}\\] Equivalentemente, la funcion de probabilidad condicional de \\(X\\) dado \\(Y = y\\) esta dada por \\[p_{X | Y = y} (x) = \\frac{p_{X Y}(x, y)}{p_{Y}(y)}\\] Definicion : Sea \\(\\mathcal{V}\\) un vector aleatorio continuo con funcion de densidad conjunta \\(f_{X Y}(x, y)\\) y funciones de probabilidad marginales para cada variable aleatoria. Sea \\(x \\in X\\) tal que \\(f_{X}(x) &gt; 0\\). La funcion de densidad condicional de Y dado \\(X = x\\) esta dada por \\[f_{Y | X = x} (y) = \\frac{f_{X Y}(x, y)}{f_{X}(x)}\\] Equivalentemente, la funcion de densidad condicional de \\(X\\) dado \\(Y = y\\) esta dada por \\[f_{X | Y = y} (x) = \\frac{f_{X Y}(x, y)}{f_{Y}(y)}\\] Observacion : Las funciones de probabilidad condicional cumplen que son una probabilidad. Podemos observar que la probabilidad condicional en vectores aleatorios es en esencia igual a cualquier probabilidad condicional, es decir, analizo probabilidades sobre un espacio de probabilidades reducido. Definicion : Sea \\(\\mathcal{V}\\) un vector aleatorio discreto. Una distribucion multinomial (Extension de la distribucion binomial) se denota \\(\\mathcal{V} ~ M(n, p_1, \\ldots, p_n)\\) 4.4 Independencia de variables aleatorias sobre un vector. Definicion : Sean \\(X_1, \\ldots, X_n\\) variables aleatorias. Se dice que son independientes si \\[P(X_1 \\in B_1, \\ldots, X_n \\in B_n) = P(X_1 \\in B_1) * \\ldots * P(X_n \\in B_n)\\] Teorema : Sean \\(X_1, \\ldots, X_n\\) variables aleatorias discretas. Son independientes si y solo si puedo escribir la probabilidad conjunta de las variables como el producto de las probabilidades marginales de las variables. Es decir: \\[p_{(X_1 \\ldots, X_n)}(X_1, \\ldots, X_n) = \\prod_{i = 1}^{n} p_{X_i}(x_i)\\] Teorema : Sean \\(X_1, \\ldots, X_n\\) variables aleatorias continuas. Son independientes si y solo si puedo escribir la probabilidad acumulada como el producto de las probabilidades acumuladas marginales de las variables. Es decir: \\[F_{(X_1 \\ldots, X_n)}(t_1, \\ldots, t_n) = \\prod_{i = 1}^{n} F_{X_i}(t_i)\\] Proposicion : Si existen funciones h y g tales que \\(p_{X Y}(x, y) = c.h(x).g(y)\\) con \\(c &gt; 0\\), entonces \\(X\\) e Y son independientes 4.5 Esperanza y covarianza de vectores aleatorios. Proposicion : Dado el vector aleatorio \\(\\mathcal{V} = &lt;X, Y&gt;\\) donde \\(X\\) e \\(Y\\) son dos variables aleatorias, entonces la esperanza del vector aleatorio esta dado por Si el vector es discreto \\[ E_{h(X, Y)} = \\sum_{x \\in Rg{x}} \\sum_{y \\in Rg{y}} h(x, y) p_{XY}(x, y) dx dy \\] Si el vector es continuo \\[ E_{h(X, Y)} = \\int_{-\\infty}^{\\infty} \\int_{-\\infty}^{\\infty} h(x, y) f_{XY}(x, y) dx dy \\] Proposicion : Si \\(X\\) e \\(Y\\) son independientes, entonces \\[E(XY) = E(X)E(Y) \\] En vectores aleatorios buscamos la relacion que hay entre los valores de las variables. Para eso utilizamos la covarianza, la cual nos da una nocion de como se relacionan. En general, la covarianza se mide como Si el vector es discreto \\[cov(X, Y) = \\sum_{x} \\sum_{y} (\\mu_x - x)(\\mu_y - y)p_{XY}(x,y)\\] Si el vector es continuo \\[cov(X, Y) = \\int_{-\\infty}^{\\infty} \\int_{-\\infty}^{\\infty} (\\mu_x - x)(\\mu_y - y)f_{XY}(x,y) dx dy\\] Proposicion : \\(cov(X, Y) = E(XY) - E(X)E(Y)\\) Definicion : Definimos coeficiente de correlacion entre dos variables a \\[\\rho(X, Y) = \\frac{cov(X, Y)}{\\sigma_X \\sigma_Y}\\] El coeficiente de correlacion determina (De alguna manera) la proporcion entre la covarianza de dos variables y sus desviaciones estandar. Tiene un poco de sentido Propiedades : \\(-1 \\leq \\rho(X, Y) \\leq 1\\) \\(\\rho(aX + b, cY +d) = sg(ac) . \\rho(X, Y)\\) \\(|\\rho(X, Y) = 1| \\leftrightarrow Y = aX + b\\) con probabilidad 1 (No lo entiendo…) "],["teorema-central-del-limite---ley-de-los-grandes-numeros.html", "5 Teorema central del limite - Ley de los grandes numeros 5.1 Desigualdad de Markov 5.2 Desigualdad de Chebyshev 5.3 Ley de los grandes numeros 5.4 Teorema central del limite", " 5 Teorema central del limite - Ley de los grandes numeros 5.1 Desigualdad de Markov 5.2 Desigualdad de Chebyshev Proposicion (Desigualdad de Chebyshev) : Sea \\(X\\) una variable aleatoria con \\(E(X) = \\mu\\) y \\(V(X) = \\frac{\\sigma^2}{\\epsilon^2}\\), entonces \\[\\forall \\epsilon &gt; 0 \\rightarrow P(|X - \\mu| &gt; \\epsilon) \\leq \\frac{\\sigma^2}{\\epsilon^2}\\] Nota : La importancia de la desigualdad de Chebyshev es que dada la esperanza y varianza, podemos encontrar una cota para las probabilidades (No necesariamente una cota ajustada). Esto nos sirve en el caso de no conocer la distribucion concreta, pues en ese caso podriamos calcular la probabilidad en vez de acotarla. Propiedades (Equivalencias de la desigualdad de Chebyshev) \\(\\forall \\epsilon &gt; 0 \\rightarrow P(|X - \\mu| \\leq \\epsilon) \\geq 1 - \\frac{\\sigma^2}{\\epsilon^2}\\) \\(\\forall k &gt; 1 \\rightarrow P(|X - \\mu| &gt; k\\sigma) \\leq\\frac{1}{k^2}\\) \\(\\forall k &gt; 1 \\rightarrow P(|X - \\mu| \\leq k\\sigma) \\geq 1 - \\frac{1}{k^2}\\) 5.3 Ley de los grandes numeros 5.3.1 Ley debil Teorema (Ley debil de los grandes numeros) : Sean \\(X_1, \\ldots, X_n\\) una secuencia de variables aleatorias i.e.e. Cada una con una esperanza y varianza \\(E(X_i) = \\mu\\), \\(V(X_i) = \\sigma^2\\). Entonces, para todo \\(\\epsilon &gt; 0\\) se cumple que \\[P(|\\frac{X_1 + \\ldots + X_n}{n}- \\mu| \\geq \\epsilon) \\rightarrow_{n \\to \\infty} 0\\] Nota : Creo que me estoy confundiendo bastante con el hecho de que las variables aleatorias caracterizan a un problema y que al momento de hacer calculos con ellas (Sumas o productos) las cosas tengan sentido. Capaz puedo ver a cada variable aleatoria independiente \\(X_i\\) como un experimento independiente donde cada una de ellas tiene la misma media y desviacion estandar, haciendo posible que la media y desviacion estandar del promedio converjan al mismo valor. 5.3.2 Ley fuerte Teorema (Ley fuerte de los grandes numeros) : Sean \\(X_1, \\ldots, X_n\\) una secuencia de variables aleatorias i.e.e. Cada una con una esperanza y varianza \\(E(X_i) = \\mu\\), \\(V(X_i) = \\sigma^2\\). Entonces: \\[\\frac{X_1 + \\ldots, X_n}{n} \\rightarrow \\mu n -&gt; \\infty\\] con probabilidad 1 (Suceso cierto) Nota : Lo que me determina la ley debil es que la probabilidad de convergencia de los valores tiende a 0 cuando la cantidad de muestras crece. Mientras que la ley fuerte determina la convergencia del promedio de las variables hacia la media. Observacion : SLLN -&gt; WLLN pero WLLN -/&gt; SLLN, pues convergencia absoluta implica la convergencia en probabilidad, pero si las variables convergen en probabilidad, no necesariamente las variables “son iguales” Nota : En el apunte de Ana Bianco hay una seccion que habla sobre distribuciones de sumas de variables aleatorias independientes. Si no mal recuerdo, esto lo vimos muy por encima en la clase. Lema (3.1 en el Ross) 5.4 Teorema central del limite Teorema (Teorema central del limite) : Sean \\(X_1, X_2, \\ldots\\) una secuencia de variables aleatorias independientes e i.i.d. Cada una de ellas con \\(E(X_i) = \\mu\\) y \\(V(X_i) = \\sigma^2 \\forall i \\in \\mathbb{N}\\). Sea Y la siguiente variable aleatoria: \\[Y = \\frac{X_1 + X_2 + \\ldots + X_n - n\\mu}{\\sigma \\sqrt{n}}\\] tiende a una distribucion normal conforme \\(n \\to \\infty\\) Corolario : Si \\(X_1, \\ldots, X_n\\) son independientes. Cada una de ellas con \\(E(X_i) = \\mu_i\\) y \\(V(X_i) = \\sigma_i^2 \\forall i \\in \\mathbb{N}\\) Si cada v.a tiene una cota superior M tal que \\(P(X_i &lt; M) = 1 \\forall i\\) y \\(\\sum_{i=1}^\\infty \\sigma_i^2 = \\infty\\), entonces \\[P(\\hat{X - \\mu_i} / \\sqrt{\\sum_{i = 1}^{n} \\sigma_i^2}) \\to \\Phi(a)\\] conforme \\(n \\to \\infty\\) "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
